{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYT1VHEYH1G8LdH1EZmjiq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kviercz/projects/blob/main/aa511_assignment2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sqPtSE5qKGoN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load Dataset\n",
        "df = pd.read_csv('M2-Advertising Dataset.csv')"
      ],
      "metadata": {
        "id": "SogwVmrCKPXy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Data preprocessing\n",
        "\n",
        "# Get info about the dataset and check for null values\n",
        "print(df.describe())\n",
        "df.info()\n",
        "df.isnull().sum()\n",
        "\n",
        "# Convert the countries column into categorical values to improve data training\n",
        "df = pd.get_dummies(df, columns=['Country'], drop_first=True)\n",
        "\n",
        "# Try to use data processing to handle the ad topic\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=50)  # Limit to top 50 features\n",
        "ad_topic_features = tfidf.fit_transform(df['Ad Topic Line']).toarray()\n",
        "ad_topic_df = pd.DataFrame(ad_topic_features, columns=tfidf.get_feature_names_out())\n",
        "\n",
        "# Concatenate TF-IDF features with the original dataframe\n",
        "df = pd.concat([df, ad_topic_df], axis=1)\n",
        "\n",
        "# Drop the original 'Ad Topic Line' column\n",
        "df = df.drop(columns=['Ad Topic Line'])\n",
        "\n",
        "# Handle non-numeric columns\n",
        "df.drop(columns=['Timestamp'], inplace=True)\n",
        "df = pd.get_dummies(df, columns=['City'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMgeSvvTKR-P",
        "outputId": "cfe5ca6d-9714-44ab-aa30-5e4c252316e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Daily Time Spent on Site          Age   Area Income  \\\n",
            "count               1000.000000  1000.000000   1000.000000   \n",
            "mean                  65.000200    36.009000  55000.000080   \n",
            "std                   15.853615     8.785562  13414.634022   \n",
            "min                   32.600000    19.000000  13996.500000   \n",
            "25%                   51.360000    29.000000  47031.802500   \n",
            "50%                   68.215000    35.000000  57012.300000   \n",
            "75%                   78.547500    42.000000  65470.635000   \n",
            "max                   91.430000    61.000000  79484.800000   \n",
            "\n",
            "       Daily Internet Usage         Male  Clicked on Ad  \n",
            "count           1000.000000  1000.000000     1000.00000  \n",
            "mean             180.000100     0.481000        0.50000  \n",
            "std               43.902339     0.499889        0.50025  \n",
            "min              104.780000     0.000000        0.00000  \n",
            "25%              138.830000     0.000000        0.00000  \n",
            "50%              183.130000     0.000000        0.50000  \n",
            "75%              218.792500     1.000000        1.00000  \n",
            "max              269.960000     1.000000        1.00000  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 10 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Daily Time Spent on Site  1000 non-null   float64\n",
            " 1   Age                       1000 non-null   int64  \n",
            " 2   Area Income               1000 non-null   float64\n",
            " 3   Daily Internet Usage      1000 non-null   float64\n",
            " 4   Ad Topic Line             1000 non-null   object \n",
            " 5   City                      1000 non-null   object \n",
            " 6   Male                      1000 non-null   int64  \n",
            " 7   Country                   1000 non-null   object \n",
            " 8   Timestamp                 1000 non-null   object \n",
            " 9   Clicked on Ad             1000 non-null   int64  \n",
            "dtypes: float64(3), int64(3), object(4)\n",
            "memory usage: 78.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Split data into train and test sets\n",
        "X = df.drop('Clicked on Ad', axis=1)\n",
        "y = df['Clicked on Ad']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "8Z9LBifhSHuU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Scale the data using Standard Scaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "ReM_K_kaSmEj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Build an ANN Classification Model\n",
        "# This function takes in different parameters to experiment with different\n",
        "# architectures and parameters. The function returns a model that can be used\n",
        "# to evaluate performance\n",
        "def build_model(hidden_layers, neurons, activation, dropout_rate, \\\n",
        "                learning_rate):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(neurons[0], activation=activation, \\\n",
        "                                 input_shape=[X_train.shape[1]]))\n",
        "\n",
        "    for i in range(1, hidden_layers):\n",
        "        model.add(keras.layers.Dense(neurons[i], activation=activation))\n",
        "        model.add(keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "    # Binary classificiation output layer\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  # model.fit(X_train, y_train, epochs=100, batch_size=16)\n",
        "  # test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "# print('Test Loss: {:.4f}'.format(test_loss))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fBW5NWQrSvSf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 Different Architectures\n",
        "# Using the function above, experiment with different architectures and parameters\n",
        "# all the models will be evaluated using the same metrics for an easier comparison\n",
        "\n",
        "# Experiment with different architectures and hyperparameters\n",
        "hyper_parameters = {\n",
        "    \"hidden_layers\": [2,3],\n",
        "    \"neurons\": [[64, 32], [128, 64, 32]],\n",
        "    \"activation\": [\"relu\", \"tanh\"],\n",
        "    \"dropout_rate\": [0.2, 0.5],\n",
        "    \"learning_rate\": [0.001, 0.01]\n",
        "}\n",
        "# Initialize results list to store the metrics for each model\n",
        "results = []\n",
        "\n",
        "# Using itertools to iterate through all the combinations of hyperparameters\n",
        "# instead of lots of nested for loops.\n",
        "for params in itertools.product(*hyper_parameters.values()):\n",
        "    params = dict(zip(hyper_parameters.keys(), params))\n",
        "\n",
        "    if len(params['neurons']) == params['hidden_layers']:\n",
        "        # Build model with given hyperparameters\n",
        "        model = build_model(**params)\n",
        "        model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=0)\n",
        "        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "        y_pred_proba = model.predict(X_test)\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "        # Collect performance metrics for this model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "        # Save results to results list for comparison\n",
        "        results.append({**params,\n",
        "                        \"test_lost\": test_loss,\n",
        "                        \"test_accuracy\": test_accuracy,\n",
        "                        \"accuracy\": accuracy,\n",
        "                        \"precision\": precision,\n",
        "                        \"recall\": recall,\n",
        "                        \"f1\": f1,\n",
        "                        \"roc_auc\": roc_auc})\n",
        "\n",
        "# Analyze the results (e.g., sort by a metric, print top performers)\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.sort_values('roc_auc', ascending=False))\n",
        "\n",
        "# Experiment with different regularization techniques\n",
        "\n",
        "# print('Test Loss: {:.4f}'.format(test_loss))\n",
        "# print('Test Accuracy: {:.4f}'.format(test_accuracy))\n",
        "\n",
        "# # ROC AUC\n",
        "# y_pred_prob = model.predict(X_test)\n",
        "# roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "# print('ROC AUC: {:.4f}'.format(roc_auc))\n",
        "\n",
        "# # Predictive classes\n",
        "# y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# # Accuracy\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print('Accuracy: {:.4f}'.format(accuracy))\n",
        "\n",
        "# # Precision\n",
        "# precision = precision_score(y_test, y_pred)\n",
        "# print('Precision: {:.4f}'.format(precision))\n",
        "\n",
        "# # Recall\n",
        "# recall = recall_score(y_test, y_pred)\n",
        "# print('Recall: {:.4f}'.format(recall))\n",
        "\n",
        "# # F1\n",
        "# f1 = f1_score(y_test, y_pred)\n",
        "# print('F1 Score: {:.4f}'.format(f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meEkASx7V3e5",
        "outputId": "e5a5962e-6e7f-4366-9494-15b371553bc4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "    hidden_layers        neurons activation  dropout_rate  learning_rate  \\\n",
            "3               2       [64, 32]       relu           0.5          0.010   \n",
            "11              3  [128, 64, 32]       relu           0.5          0.010   \n",
            "5               2       [64, 32]       tanh           0.2          0.010   \n",
            "15              3  [128, 64, 32]       tanh           0.5          0.010   \n",
            "1               2       [64, 32]       relu           0.2          0.010   \n",
            "7               2       [64, 32]       tanh           0.5          0.010   \n",
            "10              3  [128, 64, 32]       relu           0.5          0.001   \n",
            "8               3  [128, 64, 32]       relu           0.2          0.001   \n",
            "14              3  [128, 64, 32]       tanh           0.5          0.001   \n",
            "2               2       [64, 32]       relu           0.5          0.001   \n",
            "12              3  [128, 64, 32]       tanh           0.2          0.001   \n",
            "0               2       [64, 32]       relu           0.2          0.001   \n",
            "6               2       [64, 32]       tanh           0.5          0.001   \n",
            "9               3  [128, 64, 32]       relu           0.2          0.010   \n",
            "4               2       [64, 32]       tanh           0.2          0.001   \n",
            "13              3  [128, 64, 32]       tanh           0.2          0.010   \n",
            "\n",
            "    test_lost  test_accuracy  accuracy  precision    recall        f1  \\\n",
            "3    1.912305          0.875     0.875   0.825243  0.923913  0.871795   \n",
            "11   3.083233          0.800     0.800   0.964286  0.586957  0.729730   \n",
            "5    2.072814          0.860     0.860   0.801887  0.923913  0.858586   \n",
            "15   2.476305          0.825     0.825   0.747826  0.934783  0.830918   \n",
            "1    2.080643          0.865     0.865   0.957746  0.739130  0.834356   \n",
            "7    4.425359          0.690     0.690   0.602740  0.956522  0.739496   \n",
            "10   4.314683          0.695     0.695   0.609929  0.934783  0.738197   \n",
            "8    2.759161          0.770     0.770   0.691667  0.902174  0.783019   \n",
            "14   4.913490          0.660     0.660   0.578947  0.956522  0.721311   \n",
            "2    4.165091          0.645     0.645   0.571429  0.913043  0.702929   \n",
            "12   7.087603          0.505     0.505   0.480874  0.956522  0.640000   \n",
            "0    2.315503          0.755     0.755   0.779221  0.652174  0.710059   \n",
            "6    5.882755          0.575     0.575   0.521472  0.923913  0.666667   \n",
            "9    8.234589          0.460     0.460   0.460000  1.000000  0.630137   \n",
            "4    7.022677          0.495     0.495   0.474860  0.923913  0.627306   \n",
            "13   7.933949          0.480     0.480   0.468421  0.967391  0.631206   \n",
            "\n",
            "     roc_auc  \n",
            "3   0.954006  \n",
            "11  0.946558  \n",
            "5   0.942432  \n",
            "15  0.933474  \n",
            "1   0.913043  \n",
            "7   0.885165  \n",
            "10  0.878523  \n",
            "8   0.864432  \n",
            "14  0.856481  \n",
            "2   0.829207  \n",
            "12  0.796699  \n",
            "0   0.795089  \n",
            "6   0.775362  \n",
            "9   0.764291  \n",
            "4   0.733192  \n",
            "13  0.610004  \n"
          ]
        }
      ]
    }
  ]
}